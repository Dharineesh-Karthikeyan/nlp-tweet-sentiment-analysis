{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Necessities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Tf-IDf Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_added_features.csv')\n",
    "train_data.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "test_data = pd.read_csv('data/test_added_features.csv')\n",
    "test_data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_labels= train_data['sentiment']\n",
    "sentiment = list(map(lambda x: 2 if x==\"positive\" else 1 if x==\"neutral\" else 0, y_labels))\n",
    "train_data.drop('sentiment',axis=1,inplace=True)\n",
    "train_data['sentiment']=sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21465, 29285)\n"
     ]
    }
   ],
   "source": [
    "X = train_data['clean_text']\n",
    "y = train_data['sentiment']\n",
    "\n",
    "cv=TfidfVectorizer(ngram_range=(1,2), max_features=40000,min_df=2)\n",
    "X = cv.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tokenized'] = list(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final feature selection in our code is :\n",
    "        # Exclaimation marks, positive emojis, negative emojis, positive words and negative words (5 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(arr1,arr2,arr3,arr4,arr5,arr6):\n",
    "    union = list()\n",
    "    for i,v in enumerate(arr1):\n",
    "        # features is a numpy array that will contain all the features of the i-th tweet\n",
    "        features = np.append(arr1[i],arr2[i])\n",
    "        features = np.append(features,arr3[i])\n",
    "        features = np.append(features,arr4[i])\n",
    "        features = np.append(features,arr5[i])\n",
    "        features = np.append(features,arr6[i])\n",
    "        #features = np.append(features,arr7[i])\n",
    "        #features = np.append(features,arr8[i])\n",
    "        #features = np.append(features,arr9[i])\n",
    "        #features = np.append(features,arr10[i])\n",
    "        #features = np.append(features,arr11[i])\n",
    "\n",
    "        union.append(features)\n",
    "    return np.asarray(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = train_data['tokenized'].tolist()\n",
    "exc = train_data['number_of_exclamation'].tolist()\n",
    "#que = train_data['number_of_questionmark'].tolist()\n",
    "#tag = train_data['number_of_hashtag'].tolist()\n",
    "#men = train_data['number_of_mention'].tolist(\n",
    "pos_emo = train_data['number_of_positive_emo'].tolist()\n",
    "neg_emo = train_data['number_of_negative_emo'].tolist()\n",
    "pos_word = train_data['number_of_positive_words'].tolist()\n",
    "neg_word = train_data['number_of_negative_words'].tolist()\n",
    "\n",
    "X = unify(tok,exc,pos_emo,neg_emo,pos_word,neg_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = test_data['clean_text'].tolist()\n",
    "test = cv.transform(test_tweet)\n",
    "test_data['tokenized'] = list(test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = test_data['tokenized'].tolist()\n",
    "exc = test_data['number_of_exclamation'].tolist()\n",
    "#que = test_data['number_of_questionmark'].tolist()\n",
    "#tag = test_data['number_of_hashtag'].tolist()\n",
    "#men = test_data['number_of_mention'].tolist()\n",
    "#url = test_data['number_of_url'].tolist()\n",
    "#quo = test_data['number_of_quotes'].tolist()\n",
    "pos_emo = test_data['number_of_positive_emo'].tolist()\n",
    "neg_emo = test_data['number_of_negative_emo'].tolist()\n",
    "pos_word = test_data['number_of_positive_words'].tolist()\n",
    "neg_word = test_data['number_of_negative_words'].tolist()\n",
    "\n",
    "X_test = unify(tok,exc,pos_emo,neg_emo,pos_word,neg_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(X_test)\n",
    "sentiment = list(map(lambda x: 'positive' if x==2 else 'neutral' if x==1 else 'negative', y_pred))\n",
    "tweet_id = list(test_data['tweet_id'])\n",
    "d = {'tweet_id': tweet_id, 'sentiment': sentiment}\n",
    "submission = pd.DataFrame(data=d)\n",
    "submission.set_index('tweet_id',inplace=True)\n",
    "submission.head()\n",
    "submission.to_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2688\n",
       "positive    2267\n",
       "negative     443\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
